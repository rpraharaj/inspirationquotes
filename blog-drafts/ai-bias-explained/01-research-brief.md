# Research Brief: AI Bias Explained: Why AI Can Be Unfair

**Created:** 2026-01-09
**Primary Keyword:** AI bias
**Search Intent:** Informational
**Target Audience:** General tech audience, concerned citizens, developers, policymakers

---

## Key Statistics (2025-2026)

- Healthcare algorithm favored white patients over Black patients by 50%+ (Science 2025)
- Facial recognition failed 24.34% for darkest skin tones vs 0.28% for lightest (2025)
- LLMs showed bias against older women in hiring (rated lower than equal male counterparts)
- AI hiring tools gave lower scores to natural Black hairstyles (2025)
- COMPAS algorithm predicted 2x false positives for Black offenders

## Examples by Domain

### Hiring
- Amazon abandoned AI recruiter (penalized "women's" in resumes)
- Workday faced lawsuits (age, race, disability discrimination)
- LLMs rate older women lower than older men with same qualifications

### Healthcare
- Algorithm used spending as proxy for need (biased against Black patients)
- LLMs give less effective treatment recommendations for African Americans
- Skin cancer detection worse on diverse skin tones

### Facial Recognition
- 24% failure rate for dark skin vs <1% for light skin
- Higher error rates for Down syndrome, transgender individuals
- UK police system less reliable for certain ethnic groups

### Criminal Justice
- COMPAS recidivism predictions biased against Black defendants
- Predictive policing creates feedback loops in over-policed communities

---

*Research completed.*
