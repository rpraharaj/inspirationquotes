# Research Brief: Run AI on Mac

**Post ID:** #133
**Type:** Guide
**Target Word Count:** 4,000+ words

---

## Key Topics
- Apple Silicon (M1, M2, M3, M4) for AI
- Unified memory advantage explained
- Ollama on Mac setup
- LM Studio vs other tools
- MLX framework for Apple Silicon
- Model compatibility and performance
- Memory requirements for different models

## Current Apple Silicon (January 2026)
- M4 series (M4, M4 Pro, M4 Max, M4 Ultra)
- M3 series still widely used
- Unified memory: 24GB, 48GB, 64GB, 128GB options

## Internal Links
- `/blog/ollama-local-ai-guide` (#91)
- `/blog/llama-3-guide` (#92)
- `/blog/best-open-source-llms` (#93)

---

*Research completed: January 9, 2026*
